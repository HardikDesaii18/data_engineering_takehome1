{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; \n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Nyc-Jobs-data-exploration\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 200) \\\n",
    "    .config(\"spark.sql.parquet.mergeSchema\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.types import StructType\n",
    "from math import floor\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input dataframe schema is defined in JSON file \n",
    "\"\"\"\n",
    "\n",
    "with open(\"/dataset/input_schema/nyc_jobs.json\") as schema_file:\n",
    "    schema = schema_file.read()\n",
    "\n",
    "nyc_jobs_json_schema = StructType.fromJson(json.loads(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- job_id: integer (nullable = true)\n",
      " |-- agency: string (nullable = true)\n",
      " |-- posting_type: string (nullable = true)\n",
      " |-- num_of_positions: integer (nullable = true)\n",
      " |-- business_title: string (nullable = true)\n",
      " |-- civil_service_title: string (nullable = true)\n",
      " |-- title_code_no: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- job_category: string (nullable = true)\n",
      " |-- ft_pt_indicator: string (nullable = true)\n",
      " |-- salary_range_from: double (nullable = true)\n",
      " |-- salary_range_to: double (nullable = true)\n",
      " |-- salary_frequency: string (nullable = true)\n",
      " |-- work_location: string (nullable = true)\n",
      " |-- division_work_unit: string (nullable = true)\n",
      " |-- job_description: string (nullable = true)\n",
      " |-- min_qual_requirements: string (nullable = true)\n",
      " |-- preferred_skills: string (nullable = true)\n",
      " |-- additiona_information: string (nullable = true)\n",
      " |-- to_apply: string (nullable = true)\n",
      " |-- hours_shift: string (nullable = true)\n",
      " |-- work_location_1: string (nullable = true)\n",
      " |-- recruitment_contact: string (nullable = true)\n",
      " |-- residency_requirement: string (nullable = true)\n",
      " |-- posting_date: timestamp (nullable = true)\n",
      " |-- post_until: timestamp (nullable = true)\n",
      " |-- posting_updated: timestamp (nullable = true)\n",
      " |-- process_date: timestamp (nullable = true)\n",
      "\n",
      "['job_id', 'agency', 'posting_type', 'num_of_positions', 'business_title', 'civil_service_title', 'title_code_no', 'level', 'job_category', 'ft_pt_indicator', 'salary_range_from', 'salary_range_to', 'salary_frequency', 'work_location', 'division_work_unit', 'job_description', 'min_qual_requirements', 'preferred_skills', 'additiona_information', 'to_apply', 'hours_shift', 'work_location_1', 'recruitment_contact', 'residency_requirement', 'posting_date', 'post_until', 'posting_updated', 'process_date']\n"
     ]
    }
   ],
   "source": [
    "nyc_jobs_df = spark.read.schema(nyc_jobs_json_schema).\\\n",
    "        option(\"quote\", \"\\\"\").\\\n",
    "        option(\"escape\", \"\\\"\").\\\n",
    "        option(\"timestampFormat\", \"yyyy-MM-dd'T'HH:mm:ss.SSS\").\\\n",
    "        csv(\"/dataset/nyc-jobs.csv\", header=True)\n",
    "\n",
    "nyc_jobs_df.printSchema()\n",
    "print(nyc_jobs_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mod(df: DataFrame, column: str):\n",
    "    grouped_data = df.groupBy(column).agg(sf.count(column).alias(\"count\"))\n",
    "    sorted_grouped_data = grouped_data.sort(grouped_data[\"count\"].desc())\n",
    "    return sorted_grouped_data.first()[column]\n",
    "    \n",
    "def calculate_median(df: DataFrame, column: str):\n",
    "    num_rows = df.count()\n",
    "    median_index = floor(num_rows / 2)\n",
    "    return df.sort(column).take(median_index + 1)[-1][column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "# Provide a detailed analysis of source data: Column values\n",
    "\n",
    "\n",
    "analytical_columns = ['num_of_positions', 'salary_range_from', 'salary_range_to']\n",
    "\n",
    "try:\n",
    "    avg_df = nyc_jobs_df.agg(*[F.avg(F.col(c)).alias('avg_{}'.format(c)) for c in analytical_columns])\n",
    "    min_df = nyc_jobs_df.agg(*[F.min(F.col(c)).alias('min_{}'.format(c)) for c in analytical_columns])\n",
    "    max_df = nyc_jobs_df.agg(*[F.max(F.col(c)).alias('max_{}'.format(c)) for c in analytical_columns])\n",
    "    \n",
    "    \n",
    "    mode_dict = dict()\n",
    "    median_dict = dict()\n",
    "\n",
    "    # Calculate mode and median\n",
    "    mode_dict = {col: calculate_mod(nyc_jobs_df, col) for col in analytical_columns}\n",
    "    median_dict = {col: calculate_median(nyc_jobs_df, col) for col in analytical_columns}\n",
    "\n",
    "    # Convert mode and median dictionaries to DataFrames\n",
    "    mod_df = spark.createDataFrame([mode_dict])\n",
    "    median_df = spark.createDataFrame([median_dict])\n",
    "\n",
    "\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error calculating min: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum values for the selected numerical columns ->\n",
      "+--------------------+---------------------+-------------------+\n",
      "|min_num_of_positions|min_salary_range_from|min_salary_range_to|\n",
      "+--------------------+---------------------+-------------------+\n",
      "|                   1|                  0.0|              10.36|\n",
      "+--------------------+---------------------+-------------------+\n",
      "\n",
      "Maximum values for the selected numerical columns ->\n",
      "+--------------------+---------------------+-------------------+\n",
      "|max_num_of_positions|max_salary_range_from|max_salary_range_to|\n",
      "+--------------------+---------------------+-------------------+\n",
      "|                 200|             218587.0|           234402.0|\n",
      "+--------------------+---------------------+-------------------+\n",
      "\n",
      "Average values for the selected numerical columns ->\n",
      "+--------------------+---------------------+-------------------+\n",
      "|avg_num_of_positions|avg_salary_range_from|avg_salary_range_to|\n",
      "+--------------------+---------------------+-------------------+\n",
      "|  2.4959266802443993|   58904.139793856084|  85535.71162739307|\n",
      "+--------------------+---------------------+-------------------+\n",
      "\n",
      "Mod values for the selected numerical columns ->\n",
      "+----------------+-----------------+---------------+\n",
      "|num_of_positions|salary_range_from|salary_range_to|\n",
      "+----------------+-----------------+---------------+\n",
      "|               1|          52524.0|        85000.0|\n",
      "+----------------+-----------------+---------------+\n",
      "\n",
      "Median values for the selected numerical columns ->\n",
      "+----------------+-----------------+---------------+\n",
      "|num_of_positions|salary_range_from|salary_range_to|\n",
      "+----------------+-----------------+---------------+\n",
      "|               1|          58440.0|        82093.0|\n",
      "+----------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum values for the selected numerical columns ->\")\n",
    "min_df.show()\n",
    "\n",
    "print(\"Maximum values for the selected numerical columns ->\")\n",
    "max_df.show()\n",
    "\n",
    "print(\"Average values for the selected numerical columns ->\")\n",
    "avg_df.show()\n",
    "\n",
    "print(\"Mod values for the selected numerical columns ->\")\n",
    "mod_df.show()\n",
    "\n",
    "print(\"Median values for the selected numerical columns ->\")\n",
    "median_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agency': 52, 'posting_type': 2, 'business_title': 1244, 'civil_service_title': 312, 'title_code_no': 323, 'level': 14, 'job_category': 131, 'ft_pt_indicator': 3, 'salary_frequency': 3, 'work_location': 226, 'division_work_unit': 678, 'job_description': 1608, 'min_qual_requirements': 337, 'preferred_skills': 1283, 'additiona_information': 682, 'to_apply': 894, 'hours_shift': 182, 'work_location_1': 228, 'recruitment_contact': 1, 'residency_requirement': 51}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For each string column, get the distinct values count\n",
    "\"\"\"\n",
    "\n",
    "string_columns_frequency = dict()\n",
    "\n",
    "for i, column in enumerate(nyc_jobs_df.columns):\n",
    "    if nyc_jobs_df.dtypes[i][1] == \"string\":\n",
    "        unique_count = nyc_jobs_df.select(column).distinct().count()\n",
    "        string_columns_frequency[column] = unique_count\n",
    "\n",
    "\n",
    "print(string_columns_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column -> agency, Most Common Value:\n",
      "+--------------------+-----+\n",
      "|              agency|count|\n",
      "+--------------------+-----+\n",
      "|DEPT OF ENVIRONME...|  655|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> posting_type, Most Common Value:\n",
      "+------------+-----+\n",
      "|posting_type|count|\n",
      "+------------+-----+\n",
      "|    Internal| 1684|\n",
      "+------------+-----+\n",
      "\n",
      "Column -> business_title, Most Common Value:\n",
      "+--------------------+-----+\n",
      "|      business_title|count|\n",
      "+--------------------+-----+\n",
      "|Assistant Civil E...|   33|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> civil_service_title, Most Common Value:\n",
      "+--------------------+-----+\n",
      "| civil_service_title|count|\n",
      "+--------------------+-----+\n",
      "|COMMUNITY COORDIN...|  182|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> title_code_no, Most Common Value:\n",
      "+-------------+-----+\n",
      "|title_code_no|count|\n",
      "+-------------+-----+\n",
      "|        56058|  182|\n",
      "+-------------+-----+\n",
      "\n",
      "Column -> level, Most Common Value:\n",
      "+-----+-----+\n",
      "|level|count|\n",
      "+-----+-----+\n",
      "|    0| 1112|\n",
      "+-----+-----+\n",
      "\n",
      "Column -> job_category, Most Common Value:\n",
      "+--------------------+-----+\n",
      "|        job_category|count|\n",
      "+--------------------+-----+\n",
      "|Engineering, Arch...|  504|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> ft_pt_indicator, Most Common Value:\n",
      "+---------------+-----+\n",
      "|ft_pt_indicator|count|\n",
      "+---------------+-----+\n",
      "|              F| 2625|\n",
      "+---------------+-----+\n",
      "\n",
      "Column -> salary_frequency, Most Common Value:\n",
      "+----------------+-----+\n",
      "|salary_frequency|count|\n",
      "+----------------+-----+\n",
      "|          Annual| 2712|\n",
      "+----------------+-----+\n",
      "\n",
      "Column -> work_location, Most Common Value:\n",
      "+--------------------+-----+\n",
      "|       work_location|count|\n",
      "+--------------------+-----+\n",
      "|96-05 Horace Hard...|  262|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> division_work_unit, Most Common Value:\n",
      "+--------------------+-----+\n",
      "|  division_work_unit|count|\n",
      "+--------------------+-----+\n",
      "|Executive Management|   56|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> job_description, Most Common Value:\n",
      "+--------------------+-----+\n",
      "|     job_description|count|\n",
      "+--------------------+-----+\n",
      "|The New York City...|   14|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> min_qual_requirements, Most Common Value:\n",
      "+---------------------+-----+\n",
      "|min_qual_requirements|count|\n",
      "+---------------------+-----+\n",
      "| 1. A baccalaureat...|  182|\n",
      "+---------------------+-----+\n",
      "\n",
      "Column -> preferred_skills, Most Common Value:\n",
      "+----------------+-----+\n",
      "|preferred_skills|count|\n",
      "+----------------+-----+\n",
      "|   ERROR: #NAME?|   41|\n",
      "+----------------+-----+\n",
      "\n",
      "Column -> additiona_information, Most Common Value:\n",
      "+---------------------+-----+\n",
      "|additiona_information|count|\n",
      "+---------------------+-----+\n",
      "| Appointments are ...|   87|\n",
      "+---------------------+-----+\n",
      "\n",
      "Column -> to_apply, Most Common Value:\n",
      "+--------------------+-----+\n",
      "|            to_apply|count|\n",
      "+--------------------+-----+\n",
      "|Click the \"Apply ...|  296|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> hours_shift, Most Common Value:\n",
      "+-----------+-----+\n",
      "|hours_shift|count|\n",
      "+-----------+-----+\n",
      "|   35 Hours|  134|\n",
      "+-----------+-----+\n",
      "\n",
      "Column -> work_location_1, Most Common Value:\n",
      "+--------------------+-----+\n",
      "|     work_location_1|count|\n",
      "+--------------------+-----+\n",
      "|30-30 Thomson Ave...|  130|\n",
      "+--------------------+-----+\n",
      "\n",
      "Column -> recruitment_contact, Most Common Value:\n",
      "+-------------------+-----+\n",
      "|recruitment_contact|count|\n",
      "+-------------------+-----+\n",
      "|               null|    0|\n",
      "+-------------------+-----+\n",
      "\n",
      "Column -> residency_requirement, Most Common Value:\n",
      "+---------------------+-----+\n",
      "|residency_requirement|count|\n",
      "+---------------------+-----+\n",
      "| New York City res...| 1705|\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For each string column, get the Most Common value and its count\n",
    "\"\"\"\n",
    "\n",
    "for i, column in enumerate(nyc_jobs_df.columns):\n",
    "    if nyc_jobs_df.dtypes[i][1] == \"string\":\n",
    "        print(\"Column -> {}, Most Common Value:\".format(column))\n",
    "        df = nyc_jobs_df.groupBy(column).agg(F.count(column).alias(\"count\")).orderBy(F.desc(\"count\")).limit(1)\n",
    "        df.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of test function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
